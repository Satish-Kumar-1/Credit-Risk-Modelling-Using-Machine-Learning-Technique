# -*- coding: utf-8 -*-
"""Credit_Modeling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g6y59MqGzFavOYTX752x83WDAVLiMZoN
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score
from scipy.stats import chi2_contingency
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support
import warnings

a1 = pd.read_excel("/content/drive/MyDrive/case_study1.xlsx")
a2 = pd.read_excel("/content/drive/MyDrive/case_study2.xlsx")

df1 = a1.copy()
df2 = a2.copy()

print(df1.shape, df2.shape) ## (51336, 26), (51336, 62)

## Removing the rows having null values in Age column
df1 = df1.loc[df1['Age_Newest_TL'] != -99999]

df1.shape

columns_with_null_values_df2 = []

for i in df2.columns:
    if df2.loc[df2[i] == -99999].shape[0] > 10000:
        columns_with_null_values_df2.append(i)

## Dropping columns having null values
df2 = df2.drop(columns_with_null_values_df2, axis=1)

df2.shape

## Dropping rows having null values
for i in df2.columns:
    df2 = df2.loc[df2[i] != -99999]

print(df1.shape, df2.shape)

## Check Common columns
for i in list(df1.columns):
    if i in list(df2.columns):
        print(i)

## Merge the dataframes 1 and 2 using inner join

df = pd.merge(df1, df2, how = 'inner', left_on = ['PROSPECTID'],right_on = ['PROSPECTID'])

df.shape

## Now we check how many columns are categorical
l = []
for i in df.columns:
    if df[i].dtype == 'object':
        l.append(i)

l[0:5]

## Chi-square test to check the association of columns having categorial values with the Approved flag

for i in l[0:5]:
    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i],df['Approved_Flag']))
    print(i, '_____', pval)

## Check the multicollinearity between features in df
## For this we calculate the VIF value and drop the columns whose VIF > 6

# VIF for numrical columns

numeric_columns = []
for i in df.columns:
    if df[i].dtype != 'object' and i not in ['PROSPECTID', 'Approved_Flag']:
        numeric_columns.append(i)

## VIF sequentially check

vif_data = df[numeric_columns]
total_columns = vif_data.shape[1]
columns_to_be_kept = []
column_index = 0

for i in range(0, total_columns):
    vif_value = variance_inflation_factor(vif_data, column_index)
    print(column_index, '--------' , vif_value)

    if vif_value <=6:
        columns_to_be_kept.append(numeric_columns[i])
        column_index = column_index + 1

    else:
        vif_data = vif_data.drop([numeric_columns[i]], axis=1)

df.shape

len(columns_to_be_kept)

## Now we check Anova for columns_to_be_kept

from scipy.stats import f_oneway

columns_to_be_kept_numerical = []

for i in columns_to_be_kept:
    a = list(df[i])
    b = list(df['Approved_Flag'])

    group_P1 =[value for value , group in zip(a, b) if group == 'P1']
    group_P2 =[value for value , group in zip(a, b) if group == 'P2']
    group_P3 =[value for value , group in zip(a, b) if group == 'P3']
    group_P4 =[value for value , group in zip(a, b) if group == 'P4']

    f_statistics, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)

    if p_value <= 0.05:
        columns_to_be_kept_numerical.append(i)

features = columns_to_be_kept_numerical  + l[0:5]
df = df[features + ['Approved_Flag']]

## There are some categorical features, so lets do encoding

for col in l:
    print(df[col].unique())

## Lable encoding to education

df.loc[df['EDUCATION'] == 'SSC', ['EDUCATION']] = 1
df.loc[df['EDUCATION'] == '12TH', ['EDUCATION']] = 2
df.loc[df['EDUCATION'] == 'GRADUATE', ['EDUCATION']] = 3
df.loc[df['EDUCATION'] == 'UNDER GRADUATE', ['EDUCATION']] = 3
df.loc[df['EDUCATION'] == 'POST-GRADUATE', ['EDUCATION']] = 4
df.loc[df['EDUCATION'] == 'OTHERS', ['EDUCATION']] = 1
df.loc[df['EDUCATION'] == 'PROFESSIONAL', ['EDUCATION']] = 3

print(df['EDUCATION'].value_counts())

df.info()

## Some columns are still of type object

df_encoded = pd.get_dummies(df, columns= ['MARITALSTATUS' , 'GENDER' , 'last_prod_enq2', 'first_prod_enq2'])

df_encoded.info()

"""PREPROCESSING TO FIT THE MODEL"""

x = df_encoded.drop(['Approved_Flag'], axis = 1)
y = df_encoded['Approved_Flag']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)

"""# Random Forest classifier"""

rf_classifier = RandomForestClassifier(n_estimators = 200, random_state = 42)
rf_classifier.fit(x_train, y_train)

y_pred = rf_classifier.predict(x_test)

acc = accuracy_score(y_test, y_pred)
print('Accuracy is: ', acc)

precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)



for i, v in enumerate(['p1' , 'p2' , 'p3' , 'p4']):
    print(f"CLass {v}: ")
    print(f"Precision: {precision[i]}")
    print(f"Recall: {recall[i]}")
    print(f"F1 Score: {f1_score[i]}")
    print()

"""# XGboost"""

import xgboost as xgb
from sklearn.preprocessing import LabelEncoder

xgb_classifier = xgb.XGBClassifier(objective = 'multi:Softmax', num_classes = 4)

df_encoded['EDUCATION'] = df_encoded['EDUCATION'].astype(int)

y = df_encoded['Approved_Flag']
x = df_encoded.drop(['Approved_Flag'],  axis = 1)

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

x_train, x_test, y_train, y_test = train_test_split(x , y_encoded, test_size = 0.2, random_state = 42)
xgb_classifier.fit(x_train, y_train)

y_pred = xgb_classifier.predict(x_test)

acc = accuracy_score(y_test, y_pred)
print('Accuracy is: ', acc)

precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)



for i, v in enumerate(['p1' , 'p2' , 'p3' , 'p4']):
    print(f"CLass {v}: ")
    print(f"Precision: {precision[i]}")
    print(f"Recall: {recall[i]}")
    print(f"F1 Score: {f1_score[i]}")
    print()

"""# Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

x = df_encoded.drop(['Approved_Flag'], axis = 1)
y = df_encoded['Approved_Flag']

x_train, x_test, y_train, y_test = train_test_split(x , y, test_size = 0.2, random_state = 42)

dt_model = DecisionTreeClassifier(max_depth = 20, min_samples_split = 10)
dt_model.fit(x_train, y_train)
y_pred = dt_model.predict(x_test)

acc = accuracy_score(y_test, y_pred)
print('Accuracy is: ', acc)

precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)



for i, v in enumerate(['p1' , 'p2' , 'p3' , 'p4']):
    print(f"CLass {v}: ")
    print(f"Precision: {precision[i]}")
    print(f"Recall: {recall[i]}")
    print(f"F1 Score: {f1_score[i]}")
    print()

"""#Having good metrics in XGBOOST, now we do the HYPERPARAMETRIC tune"""

from sklearn.model_selection import GridSearchCV
x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size = 0.2, random_state = 42)


xgb_model = xgb.XGBClassifier(objective = 'multi:softmax', num_class = 4)


## Define the parameter grid for hyperparameter tuning

param_grid = {
    'n_estimators' : [50, 100, 200],
    'max_depth' : [3, 5, 7],
    'learning_rate' : [0.01, 0.1, 0.2]
}

grid_search = GridSearchCV(estimator = xgb_model, param_grid = param_grid, cv = 3, scoring = 'accuracy', n_jobs = -1)
grid_search.fit(x_train, y_train)

print('Best  Hyperparameter: ', grid_search.best_params_)

## Evaluate the model with the best hyperparameters on the test set

best_model = grid_search.best_estimator_
accuracy = best_model.score(x_test, y_test)
print('Test Accuracy: ', accuracy)

"""# For Better understanding of hyperparameter tuning I am going to use loop"""

## Define the hyperparameter grid

param_grid = {
        'colsample_bytree' : [0.1, 0.3, 0.5, 0.7, 0.9],
        'learning_rate' : [0.001, 0.01, 0.1, 1],
        'max_depth' : [3, 5, 8, 10],
        'alpha' : [1, 10, 100],
        'n_estimators' : [10, 50, 100]
}

index = 0

answers_grid = {
        'combination' : [],
        'train_accuracy' : [],
        'test_accuracy' : [],
        'colsample_bytree' : [],
        'learning_rate' : [],
        'max_depth' : [],
        'alpha' : [],
        'n_estimators' : []
}

for colsample_bytree in param_grid['colsample_bytree']:
    for learning_rate in param_grid['learning_rate']:
        for max_depth in param_grid['max_depth']:
            for alpha in param_grid['alpha']:
                for n_estimators in param_grid['n_estimators']:
                    index = index + 1

                    model = xgb.XGBClassifier(
                        objective = 'mulit : softmax',
                        num_class = 4,
                        colsample_bytree = colsample_bytree,
                        learning_rate = learning_rate,
                        max_depth = max_depth,
                        alpha = alpha,
                        n_estimators = n_estimators
                    )

                    y = df_encoded['Approved_Flag']
                    x = df_encoded.drop(['Approved_Flag'], axis = 1)

                    label_encoder = LabelEncoder()
                    y_encoded = label_encoder.fit_transform(y)

                    x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size = 0.2, random_state = 42)

                    model.fit(x_train, y_train)

                    y_pred_train = model.predict(x_train)
                    y_pred_test = model.predict(x_test)

                    train_accuracy = accuracy_score(y_train, y_pred_train)
                    test_accuracy = accuracy_score(y_test, y_pred_test)

                    answers_grid['combination'].append(index)
                    answers_grid['train_accuracy'].append(train_accuracy)
                    answers_grid['test_accuracy'].append(test_accuracy)
                    answers_grid['colsample_bytree'].append(colsample_bytree)
                    answers_grid['learning_rate'].append(learning_rate)
                    answers_grid['max_depth'].append(max_depth)
                    answers_grid['alpha'].append(alpha)
                    answers_grid['n_estimators'].append(n_estimators)


                    # print(f'Combination {index}')
                    # print(f'colsample_bytree: {colsample_bytree}, learning_rate: {learning_rate}, max_depth = {max_depth}, alpha: {alpha}, n_estimators : {n_estimators}')
                    # print(f'Train Accuracy: {train_accuracy}')
                    # print(f'Test_accuracy: {test_accuracy}')
                    # print('-'*30)


print(f'Maximum test accuracy is : {test_accuracy.max()}')
print(f'Maximum_train_accuracy is: {train_accuracy.max()}')

!pip3= install openpyxl

accuracy_dataset = pd.DataFrame(answers_grid)
df.to_excel(excel_writer = "/content/accuracy.xlsx", engine = 'openpyxl')

